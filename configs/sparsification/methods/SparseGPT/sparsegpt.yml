base:
    seed: &seed 42
model:
    type: Llama
    path: model path
    torch_dtype: auto
calib:
    name: pileval
    download: False
    path: calib data path
    n_samples: 128
    bs: -1
    seq_len: 512
    preproc: txt_general_preproc
    seed: *seed
eval:
    eval_pos: [transformed]
    name: [wikitext2, c4]
    download: False
    path: eval data path
    bs: 1
    seq_len: 2048
sparse:
    method: SparseGPT
    weight:
        sparsity: 0.5
        # granularity: per_group
        # group_size: 128
    special:
        # actorder: False
        # static_groups: False
        unstructured: True
        semi_structured: False
        prunen: 0
        prunem: 0
        structured: False
        percdamp: 0.01
        blocksize: 128
        true_sequential: True
        # owq: True
        #target bit is 4.01
        # n_outs: [6, 6, 6, 6, 2, 2, 6]
    sparsity_out: False
save:
    save_trans: False
    save_path: ./save
